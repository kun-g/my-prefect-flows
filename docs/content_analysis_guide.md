# æ™ºèƒ½å†…å®¹åˆ†æä¸è¯„ä»·ç³»ç»Ÿ (ADR-004)

## ğŸ“‹ ç³»ç»Ÿæ¦‚è¿°

æ™ºèƒ½å†…å®¹åˆ†æç³»ç»Ÿæ˜¯ä¸€ä¸ªåŸºäºLLMçš„å†…å®¹è¯„ä»·å·¥å…·ï¼Œèƒ½å¤Ÿè‡ªåŠ¨åˆ†ææŠ€æœ¯æ–‡ç« å¹¶æä¾›å¤šç»´åº¦è¯„åˆ†ã€æ ‡ç­¾åˆ†ç±»å’Œæ‘˜è¦ç”ŸæˆåŠŸèƒ½ã€‚

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### æ ¸å¿ƒç»„ä»¶

1. **ContentAnalysis** - å†…å®¹åˆ†æç»“æœæ•°æ®ç»“æ„
2. **ContentOptimizer** - æ™ºèƒ½æ–‡æœ¬ä¼˜åŒ–å™¨
3. **ContentAnalyzer** - ä¸»åˆ†ææ§åˆ¶å™¨ï¼ˆç›´æ¥é›†æˆLiteLLMï¼‰
4. **Prefectå·¥ä½œæµ** - æ‰¹é‡å¤„ç†å’Œä»»åŠ¡ç®¡ç†

### æŠ€æœ¯æ ˆ

- **LiteLLM**: å¤šæ¨¡å‹æŠ½è±¡å±‚ï¼Œæä¾›ç»Ÿä¸€çš„APIæ¥å£
- **OpenAI GPT-4o/4o-mini**: ä¸»è¦åˆ†ææ¨¡å‹
- **Anthropic Claude-3-Sonnet**: å¤‡é€‰æ¨¡å‹ï¼ˆå¯é€‰ï¼‰
- **Prefect**: å·¥ä½œæµç¼–æ’

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
# ä½¿ç”¨uvï¼ˆæ¨èï¼‰
uv sync

# æˆ–ä½¿ç”¨pip
pip install litellm openai prefect beautifulsoup4
```

### 2. é…ç½®APIå¯†é’¥

```bash
# è®¾ç½®OpenAI APIå¯†é’¥
export OPENAI_API_KEY="your-openai-api-key"

# å¯é€‰ï¼šè®¾ç½®Anthropic APIå¯†é’¥
export ANTHROPIC_API_KEY="your-anthropic-api-key"
```

### 3. åŸºæœ¬ä½¿ç”¨

```python
import asyncio
from lib.content_analyzer import ContentAnalyzer

async def analyze_content():
    analyzer = ContentAnalyzer()
    
    analysis = await analyzer.analyze_content(
        content="ä½ çš„æ–‡ç« å†…å®¹...",
        title="æ–‡ç« æ ‡é¢˜",
        url="https://example.com/article"
    )
    
    print(f"è¯„åˆ†: {analysis.reading_score:.1f}/10")
    print(f"æ ‡ç­¾: {analysis.tags}")
    print(f"æ‘˜è¦: {analysis.summary}")

# è¿è¡Œåˆ†æ
asyncio.run(analyze_content())
```

### 4. è¿è¡Œç¤ºä¾‹

```bash
# è¿è¡ŒåŸºæœ¬æµ‹è¯•
python test_content_analysis.py

# è¿è¡Œç¤ºä¾‹åˆ†æ
python example_content_analysis.py

# è¿è¡ŒPrefectå·¥ä½œæµ
python flows/content_analysis_flow.py
```

## ğŸ“Š è¯„åˆ†ä½“ç³»

### äº”ç»´åº¦è¯„åˆ†

| ç»´åº¦ | æƒé‡ | è¯´æ˜ |
|------|------|------|
| å®ç”¨æ€§ | 25% | èƒ½å¦ç›´æ¥åº”ç”¨åˆ°å·¥ä½œä¸­ |
| å­¦ä¹ ä»·å€¼ | 25% | èƒ½å­¦åˆ°æ–°çŸ¥è¯†/æŠ€èƒ½çš„ç¨‹åº¦ |
| æ—¶æ•ˆæ€§ | 20% | ä¿¡æ¯æ–°é²œåº¦å’Œå½“å‰ç›¸å…³æ€§ |
| æŠ€æœ¯æ·±åº¦ | 15% | æŠ€æœ¯å«é‡å’Œå¤æ‚åº¦ |
| å®Œæ•´æ€§ | 15% | å†…å®¹å®Œæ•´æ€§å’Œé€»è¾‘æ€§ |

### éš¾åº¦ç­‰çº§

- **åˆçº§**: é€‚åˆåˆå­¦è€…ï¼ŒåŸºç¡€æ¦‚å¿µä»‹ç»
- **ä¸­çº§**: éœ€è¦ä¸€å®šåŸºç¡€ï¼Œå®é™…åº”ç”¨åœºæ™¯
- **é«˜çº§**: éœ€è¦æ·±åšåŸºç¡€ï¼Œå¤æ‚æŠ€æœ¯å®ç°

## ğŸ·ï¸ æ ‡ç­¾ä½“ç³»

### æŠ€æœ¯æ ˆæ ‡ç­¾
Python, JavaScript, Java, Go, React, Vue, Docker, Kubernetes, AWSç­‰

### å†…å®¹ç±»å‹æ ‡ç­¾
æ•™ç¨‹, æŒ‡å—, æœ€ä½³å®è·µ, æ¡ˆä¾‹ç ”ç©¶, å·¥å…·ä»‹ç»ç­‰

### åº”ç”¨åœºæ™¯æ ‡ç­¾
Webå¼€å‘, ç§»åŠ¨å¼€å‘, åç«¯å¼€å‘, DevOps, æ•°æ®ç§‘å­¦ç­‰

### è¡Œä¸šé¢†åŸŸæ ‡ç­¾
ç”µå•†, é‡‘è, åŒ»ç–—, æ•™è‚², æ¸¸æˆç­‰

## âš™ï¸ é…ç½®è¯´æ˜

### LLMé…ç½®æ–‡ä»¶

å¤åˆ¶å¹¶ä¿®æ”¹é…ç½®æ¨¡æ¿ï¼š

```bash
cp config/llm_config.json.example config/llm_config.json
```

é…ç½®æ–‡ä»¶ç»“æ„ï¼š

```json
{
  "models": [
    {
      "model_name": "gpt-4o-mini",
      "litellm_params": {
        "model": "gpt-4o-mini",
        "api_key": "your-api-key",
        "timeout": 30
      },
      "cost_per_1k_tokens": 0.000150
    }
  ],
  "default_model": "gpt-4o-mini",
  "fallback_strategy": "gpt-4o-mini"
}
```

### ç¯å¢ƒå˜é‡

```bash
# å¿…éœ€
OPENAI_API_KEY=your-openai-api-key

# å¯é€‰
ANTHROPIC_API_KEY=your-anthropic-api-key
LLM_CONFIG_PATH=config/llm_config.json
MAX_CONCURRENT_REQUESTS=5
```

## ğŸ”„ Prefectå·¥ä½œæµ

### å•ç«™ç‚¹å†…å®¹åˆ†æ

```python
from flows.content_analysis_flow import content_analysis_flow

# è¿è¡Œå·¥ä½œæµ
await content_analysis_flow(
    sitemap_url="https://example.com/sitemap.xml",
    max_articles=20,
    output_dir="output/analysis"
)
```

### æ‰¹é‡ç«™ç‚¹åˆ†æ

```python
from flows.content_analysis_flow import batch_site_analysis_flow

sites = [
    {"name": "site1", "sitemap_url": "https://site1.com/sitemap.xml"},
    {"name": "site2", "sitemap_url": "https://site2.com/sitemap.xml"}
]

await batch_site_analysis_flow(
    sites_config=sites,
    max_articles_per_site=10
)
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### å¹¶å‘æ§åˆ¶

```python
# è°ƒæ•´å¹¶å‘æ•°
analyzer = ContentAnalyzer()
results = await analyzer.batch_analyze(
    articles=articles,
    max_concurrent=3  # æ§åˆ¶å¹¶å‘è¯·æ±‚æ•°
)
```

### å†…å®¹ä¼˜åŒ–

```python
# æ™ºèƒ½æˆªæ–­é•¿æ–‡æœ¬
optimizer = ContentOptimizer(max_tokens=4000)
optimized_content, metadata = optimizer.optimize_for_analysis(content)
```

### æˆæœ¬æ§åˆ¶

- æ‘˜è¦å’Œæ ‡ç­¾ä½¿ç”¨`gpt-4o-mini`ï¼ˆä¾¿å®œï¼‰
- è¯„åˆ†ä½¿ç”¨`gpt-4o`ï¼ˆæ›´å‡†ç¡®ï¼‰
- è‡ªåŠ¨é™çº§æœºåˆ¶
- æˆæœ¬è·Ÿè¸ªå’Œé¢„ç®—æ§åˆ¶

## ğŸ’° æˆæœ¬ä¼°ç®—

| ä»»åŠ¡ç±»å‹ | æ¨¡å‹ | é¢„ä¼°Token | å•æ¬¡æˆæœ¬ |
|----------|------|-----------|----------|
| æ‘˜è¦ç”Ÿæˆ | gpt-4o-mini | 1000 | $0.0002 |
| æ ‡ç­¾æå– | gpt-4o-mini | 800 | $0.0001 |
| è¯„åˆ†è®¡ç®— | gpt-4o | 1500 | $0.0075 |
| **æ€»è®¡** | - | **3300** | **$0.0078** |

æ—¥å¤„ç†100ç¯‡æ–‡ç« æˆæœ¬çº¦ï¼š**$0.78**

## ğŸ§ª æµ‹è¯•å’ŒéªŒè¯

### è¿è¡Œæµ‹è¯•å¥—ä»¶

```bash
# åŸºç¡€åŠŸèƒ½æµ‹è¯•
python test_content_analysis.py

# æ€§èƒ½æµ‹è¯•
python -m pytest tests/ -v

# è¦†ç›–ç‡æµ‹è¯•
coverage run -m pytest && coverage report
```

### éªŒè¯åˆ†æè´¨é‡

1. **ä¸€è‡´æ€§æµ‹è¯•**: åŒä¸€æ–‡ç« å¤šæ¬¡åˆ†æçš„è¯„åˆ†å·®å¼‚åº”<0.5åˆ†
2. **å‡†ç¡®æ€§æµ‹è¯•**: æ ‡ç­¾å‡†ç¡®ç‡åº”>85%
3. **æ‘˜è¦è´¨é‡**: æ‘˜è¦åº”åŒ…å«æ ¸å¿ƒä¿¡æ¯ï¼Œé•¿åº¦150-200å­—

## ğŸ“ è¾“å‡ºæ ¼å¼

### åˆ†æç»“æœJSON

```json
{
  "analyzed_at": "2024-01-15T10:30:00",
  "total_articles": 10,
  "average_score": 7.8,
  "articles": [
    {
      "url": "https://example.com/article",
      "title": "æ–‡ç« æ ‡é¢˜",
      "summary": "æ–‡ç« æ‘˜è¦...",
      "tags": ["Python", "Webå¼€å‘"],
      "reading_score": 8.2,
      "reading_time_minutes": 6,
      "difficulty_level": "ä¸­çº§",
      "score_breakdown": {
        "å®ç”¨æ€§": 8.5,
        "å­¦ä¹ ä»·å€¼": 8.0,
        "æ—¶æ•ˆæ€§": 7.8,
        "æŠ€æœ¯æ·±åº¦": 8.0,
        "å®Œæ•´æ€§": 8.2
      },
      "confidence_score": 0.85
    }
  ]
}
```

### åˆ†ææŠ¥å‘ŠMarkdown

è‡ªåŠ¨ç”ŸæˆåŒ…å«ç»Ÿè®¡ä¿¡æ¯å’Œé«˜ä»·å€¼æ–‡ç« æ¨èçš„MarkdownæŠ¥å‘Šã€‚

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **APIå¯†é’¥é”™è¯¯**
   ```bash
   export OPENAI_API_KEY="your-correct-api-key"
   ```

2. **è¯·æ±‚è¶…æ—¶**
   - å¢åŠ timeouté…ç½®
   - é™ä½å¹¶å‘æ•°
   - æ£€æŸ¥ç½‘ç»œè¿æ¥

3. **æˆæœ¬è¿‡é«˜**
   - ä½¿ç”¨æ›´å¤šminiæ¨¡å‹
   - å‡å°‘æœ€å¤§tokenæ•°
   - ä¼˜åŒ–å†…å®¹æˆªæ–­ç­–ç•¥

4. **åˆ†æè´¨é‡å·®**
   - è°ƒæ•´system prompts
   - å¢åŠ contextä¿¡æ¯
   - ä½¿ç”¨æ›´å¼ºçš„æ¨¡å‹

### è°ƒè¯•æ¨¡å¼

```python
# å¯ç”¨è¯¦ç»†æ—¥å¿—
import litellm
litellm.set_verbose = True

# æŸ¥çœ‹ä½¿ç”¨ç»Ÿè®¡
stats = analyzer.get_usage_statistics()
print(stats)
```

## ğŸš€ æ‰©å±•å¼€å‘

### æ·»åŠ æ–°æ¨¡å‹

åœ¨é…ç½®æ–‡ä»¶ä¸­æ·»åŠ æ–°æ¨¡å‹ï¼š

```json
{
  "model_name": "claude-3-sonnet",
  "litellm_params": {
    "model": "anthropic/claude-3-sonnet-20240229",
    "api_key": "your-anthropic-key"
  }
}
```

### è‡ªå®šä¹‰è¯„åˆ†ç»´åº¦

ä¿®æ”¹`ScoreDimensions`ç±»ï¼š

```python
class ScoreDimensions:
    NEW_DIMENSION = "æ–°ç»´åº¦"
    
    @classmethod
    def get_weights(cls):
        return {
            cls.PRACTICALITY: 0.20,
            cls.LEARNING_VALUE: 0.20,
            cls.NEW_DIMENSION: 0.15,
            # ... å…¶ä»–ç»´åº¦
        }
```

### è‡ªå®šä¹‰æ ‡ç­¾

æ‰©å±•`TagCategories`ç±»ï¼š

```python
class TagCategories:
    CUSTOM_TAGS = {"è‡ªå®šä¹‰æ ‡ç­¾1", "è‡ªå®šä¹‰æ ‡ç­¾2"}
    
    @classmethod
    def get_all_tags(cls):
        return cls.TECH_STACK | cls.CONTENT_TYPE | cls.CUSTOM_TAGS
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [ADR-004: æ™ºèƒ½å†…å®¹åˆ†æç³»ç»Ÿæ¶æ„è®¾è®¡](docs/adr/004-intelligent-content-analysis-system.md)
- [LiteLLMæ–‡æ¡£](https://docs.litellm.ai/)
- [OpenAI APIæ–‡æ¡£](https://platform.openai.com/docs/)
- [Prefectæ–‡æ¡£](https://docs.prefect.io/)

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. Forké¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
3. æäº¤æ›´æ”¹
4. è¿è¡Œæµ‹è¯•
5. åˆ›å»ºPull Request

## ğŸ“„ è®¸å¯è¯

MIT License - è¯¦è§LICENSEæ–‡ä»¶