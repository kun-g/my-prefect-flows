#!/usr/bin/env python3
"""
æ™ºèƒ½å†…å®¹åˆ†æç³»ç»Ÿéƒ¨ç½²è„šæœ¬
è‡ªåŠ¨åŒ–é…ç½®å’Œéƒ¨ç½²æµç¨‹
"""

import os
import sys
import json
import shutil
from pathlib import Path


def check_environment():
    """æ£€æŸ¥ç¯å¢ƒä¾èµ–"""
    print("ğŸ” æ£€æŸ¥ç¯å¢ƒä¾èµ–...")
    
    # æ£€æŸ¥Pythonç‰ˆæœ¬
    python_version = sys.version_info
    if python_version < (3, 8):
        print(f"âŒ Pythonç‰ˆæœ¬è¿‡ä½: {python_version.major}.{python_version.minor}")
        print("ğŸ’¡ éœ€è¦Python 3.8æˆ–æ›´é«˜ç‰ˆæœ¬")
        return False
    
    print(f"âœ… Pythonç‰ˆæœ¬: {python_version.major}.{python_version.minor}.{python_version.micro}")
    
    # æ£€æŸ¥å¿…è¦çš„åŒ…
    required_packages = [
        ('litellm', 'litellm'), 
        ('tiktoken', 'tiktoken'), 
        ('prefect', 'prefect'), 
        ('beautifulsoup4', 'bs4'), 
        ('python-dotenv', 'dotenv'), 
        ('requests', 'requests')
    ]
    
    missing_packages = []
    for package_name, import_name in required_packages:
        try:
            __import__(import_name)
            print(f"âœ… {package_name}: å·²å®‰è£…")
        except ImportError:
            missing_packages.append(package_name)
            print(f"âŒ {package_name}: æœªå®‰è£…")
    
    if missing_packages:
        print(f"\nğŸ’¡ è¯·å®‰è£…ç¼ºå¤±çš„åŒ…:")
        print(f"   pip install {' '.join(missing_packages)}")
        return False
    
    return True


def setup_configuration():
    """è®¾ç½®é…ç½®æ–‡ä»¶"""
    print("\nâš™ï¸ è®¾ç½®é…ç½®æ–‡ä»¶...")
    
    config_dir = Path("config")
    config_dir.mkdir(exist_ok=True)
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰é…ç½®æ–‡ä»¶
    config_file = config_dir / "llm_config.json"
    example_file = config_dir / "llm_config.json.example"
    
    if config_file.exists():
        print("âœ… é…ç½®æ–‡ä»¶å·²å­˜åœ¨")
        return True
    
    if not example_file.exists():
        print("âŒ é…ç½®æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    # å¤åˆ¶ç¤ºä¾‹é…ç½®
    shutil.copy(example_file, config_file)
    print(f"âœ… å·²åˆ›å»ºé…ç½®æ–‡ä»¶: {config_file}")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key:
        # æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„APIå¯†é’¥
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            # æ›´æ–°APIå¯†é’¥
            for model in config.get("models", []):
                if "openai" in model.get("model_name", "").lower():
                    model["litellm_params"]["api_key"] = api_key
            
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            
            print("âœ… å·²è‡ªåŠ¨é…ç½®OpenAI APIå¯†é’¥")
        except Exception as e:
            print(f"âš ï¸ è‡ªåŠ¨é…ç½®APIå¯†é’¥å¤±è´¥: {e}")
    else:
        print("âš ï¸ æœªæ£€æµ‹åˆ°OPENAI_API_KEYç¯å¢ƒå˜é‡")
        print("ğŸ’¡ è¯·æ‰‹åŠ¨ç¼–è¾‘é…ç½®æ–‡ä»¶æˆ–è®¾ç½®ç¯å¢ƒå˜é‡")
    
    return True


def setup_directories():
    """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
    print("\nğŸ“ åˆ›å»ºç›®å½•ç»“æ„...")
    
    directories = [
        "output",
        "output/content_analysis", 
        "output/batch_analysis",
        "logs",
        "tmp"
    ]
    
    for directory in directories:
        Path(directory).mkdir(parents=True, exist_ok=True)
        print(f"âœ… åˆ›å»ºç›®å½•: {directory}")
    
    return True


def create_gitignore():
    """æ›´æ–°.gitignoreæ–‡ä»¶"""
    print("\nğŸ“ æ›´æ–°.gitignore...")
    
    gitignore_entries = [
        "# æ™ºèƒ½å†…å®¹åˆ†æç³»ç»Ÿ",
        "config/llm_config.json",
        "output/",
        "logs/",
        "tmp/",
        "*.log",
        "__pycache__/",
        "*.pyc",
        ".pytest_cache/",
        ".coverage"
    ]
    
    gitignore_path = Path(".gitignore")
    
    if gitignore_path.exists():
        with open(gitignore_path, 'r', encoding='utf-8') as f:
            existing_content = f.read()
    else:
        existing_content = ""
    
    new_entries = []
    for entry in gitignore_entries:
        if entry not in existing_content:
            new_entries.append(entry)
    
    if new_entries:
        with open(gitignore_path, 'a', encoding='utf-8') as f:
            if existing_content and not existing_content.endswith('\n'):
                f.write('\n')
            f.write('\n'.join(new_entries) + '\n')
        
        print(f"âœ… å·²æ·»åŠ  {len(new_entries)} æ¡.gitignoreè§„åˆ™")
    else:
        print("âœ… .gitignoreå·²æ˜¯æœ€æ–°")
    
    return True


def test_basic_functionality():
    """æµ‹è¯•åŸºæœ¬åŠŸèƒ½"""
    print("\nğŸ§ª æµ‹è¯•åŸºæœ¬åŠŸèƒ½...")
    
    try:
        sys.path.append('.')
        from lib.content_analysis import ContentAnalysis, ScoreDimensions
        from lib.content_optimizer import ContentOptimizer
        from lib.llm_manager import LLMManager
        
        # æµ‹è¯•æ•°æ®ç»“æ„
        weights = ScoreDimensions.get_weights()
        print(f"âœ… è¯„åˆ†ç»´åº¦: {len(weights)}ä¸ª")
        
        # æµ‹è¯•å†…å®¹ä¼˜åŒ–å™¨
        optimizer = ContentOptimizer()
        test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ã€‚" * 100
        tokens = optimizer.estimate_tokens(test_text)
        print(f"âœ… Tokenè®¡ç®—: {tokens}")
        
        # æµ‹è¯•LLMç®¡ç†å™¨
        manager = LLMManager()
        print("âœ… LLMç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        return True
        
    except Exception as e:
        print(f"âŒ åŸºæœ¬åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False


def create_env_template():
    """åˆ›å»ºç¯å¢ƒå˜é‡æ¨¡æ¿"""
    print("\nğŸ“‹ åˆ›å»ºç¯å¢ƒå˜é‡æ¨¡æ¿...")
    
    env_template = """# æ™ºèƒ½å†…å®¹åˆ†æç³»ç»Ÿç¯å¢ƒå˜é‡é…ç½®

# OpenAI APIé…ç½® (å¿…éœ€)
OPENAI_API_KEY=your-openai-api-key-here

# Anthropic APIé…ç½® (å¯é€‰)
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# LLMé…ç½®æ–‡ä»¶è·¯å¾„ (å¯é€‰)
LLM_CONFIG_PATH=config/llm_config.json

# å¹¶å‘æ§åˆ¶ (å¯é€‰)
MAX_CONCURRENT_REQUESTS=5
DEFAULT_MAX_TOKENS=4000

# æˆæœ¬æ§åˆ¶ (å¯é€‰)
DAILY_BUDGET=10.0
COST_ALERT_THRESHOLD=0.8

# æ—¥å¿—çº§åˆ« (å¯é€‰)
LOG_LEVEL=INFO

# è¾“å‡ºç›®å½• (å¯é€‰)
OUTPUT_DIR=output
"""
    
    env_file = Path(".env.content_analysis")
    
    if not env_file.exists():
        with open(env_file, 'w', encoding='utf-8') as f:
            f.write(env_template)
        print(f"âœ… å·²åˆ›å»ºç¯å¢ƒå˜é‡æ¨¡æ¿: {env_file}")
        print("ğŸ’¡ è¯·å¤åˆ¶åˆ°.envå¹¶å¡«å…¥çœŸå®å€¼")
    else:
        print("âœ… ç¯å¢ƒå˜é‡æ¨¡æ¿å·²å­˜åœ¨")
    
    return True


def deploy_prefect_flows():
    """éƒ¨ç½²Prefectå·¥ä½œæµ"""
    print("\nğŸš€ éƒ¨ç½²Prefectå·¥ä½œæµ...")
    
    try:
        import subprocess
        
        # æ£€æŸ¥PrefectçŠ¶æ€
        result = subprocess.run(['prefect', 'version'], 
                              capture_output=True, text=True)
        if result.returncode != 0:
            print("âŒ Prefectæœªæ­£ç¡®å®‰è£…")
            return False
        
        print(f"âœ… Prefectç‰ˆæœ¬: {result.stdout.strip()}")
        
        # éƒ¨ç½²å·¥ä½œæµ
        flow_file = "flows/content_analysis_flow.py"
        if Path(flow_file).exists():
            print(f"ğŸ“¦ éƒ¨ç½²å·¥ä½œæµ: {flow_file}")
            
            deploy_cmd = [
                'prefect', 'deployment', 'build',
                f'{flow_file}:content_analysis_flow',
                '-p', 'local-process',
                '--name', 'content-analysis',
                '--description', 'æ™ºèƒ½å†…å®¹åˆ†æå·¥ä½œæµ'
            ]
            
            result = subprocess.run(deploy_cmd, capture_output=True, text=True)
            if result.returncode == 0:
                print("âœ… å·¥ä½œæµéƒ¨ç½²æˆåŠŸ")
                print("ğŸ’¡ ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯åŠ¨worker:")
                print("   prefect worker start --pool default")
            else:
                print(f"âš ï¸ å·¥ä½œæµéƒ¨ç½²å¤±è´¥: {result.stderr}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Prefectéƒ¨ç½²å¤±è´¥: {e}")
        return False


def generate_deployment_summary():
    """ç”Ÿæˆéƒ¨ç½²æ€»ç»“"""
    print("\nğŸ“Š éƒ¨ç½²æ€»ç»“")
    print("=" * 50)
    
    print("âœ… æ™ºèƒ½å†…å®¹åˆ†æç³»ç»Ÿéƒ¨ç½²å®Œæˆ!")
    
    print("\nğŸ“ ä¸‹ä¸€æ­¥æ“ä½œ:")
    print("1. è®¾ç½®APIå¯†é’¥:")
    print("   export OPENAI_API_KEY='your-api-key'")
    
    print("\n2. è¿è¡Œæµ‹è¯•:")
    print("   python test_content_analysis.py")
    
    print("\n3. è¿è¡Œç¤ºä¾‹:")
    print("   python example_content_analysis.py")
    
    print("\n4. å¯åŠ¨Prefectå·¥ä½œæµ:")
    print("   prefect worker start --pool default")
    
    print("\n5. è¿è¡Œå†…å®¹åˆ†æ:")
    print("   python flows/content_analysis_flow.py")
    
    print(f"\nğŸ“š æ–‡æ¡£ä½ç½®:")
    print(f"   docs/content_analysis_guide.md")
    
    print(f"\nâš™ï¸ é…ç½®æ–‡ä»¶:")
    print(f"   config/llm_config.json")
    print(f"   .env.content_analysis")


def main():
    """ä¸»éƒ¨ç½²å‡½æ•°"""
    print("ğŸš€ æ™ºèƒ½å†…å®¹åˆ†æç³»ç»Ÿéƒ¨ç½²è„šæœ¬")
    print("=" * 50)
    
    steps = [
        ("æ£€æŸ¥ç¯å¢ƒ", check_environment),
        ("è®¾ç½®é…ç½®", setup_configuration),
        ("åˆ›å»ºç›®å½•", setup_directories),
        ("æ›´æ–°gitignore", create_gitignore),
        ("åˆ›å»ºç¯å¢ƒæ¨¡æ¿", create_env_template),
        ("æµ‹è¯•åŠŸèƒ½", test_basic_functionality),
        ("éƒ¨ç½²å·¥ä½œæµ", deploy_prefect_flows)
    ]
    
    for step_name, step_func in steps:
        print(f"\n{'='*20} {step_name} {'='*20}")
        
        try:
            success = step_func()
            if not success:
                print(f"âŒ {step_name}å¤±è´¥ï¼Œè¯·æ£€æŸ¥å¹¶é‡è¯•")
                return False
        except Exception as e:
            print(f"âŒ {step_name}å¼‚å¸¸: {e}")
            return False
    
    generate_deployment_summary()
    return True


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)